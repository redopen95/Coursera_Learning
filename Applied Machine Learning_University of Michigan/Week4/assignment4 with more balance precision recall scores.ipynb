{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d305e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e532a7b0bbaf722cc8e5496bfde02472",
     "grade": false,
     "grade_id": "cell-24e3b5e89f5669c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the Jupyter Notebook FAQ course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be71ec1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ddd869ec642dbe6404672b445fd4dd1",
     "grade": false,
     "grade_id": "cell-6757b7ecd16ad875",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 4 - Predicting and understanding viewer engagement with educational videos \n",
    "\n",
    "With the accelerating popularity of online educational experiences, the role of online lectures and other educational video continues to increase in scope and importance. Open access educational repositories such as <a href=\"http://videolectures.net/\">videolectures.net</a>, as well as Massive Open Online Courses (MOOCs) on platforms like Coursera, have made access to many thousands of lectures and tutorials an accessible option for millions of people around the world. Yet this impressive volume of content has also led to a challenge in how to find, filter, and match these videos with learners. This assignment gives you an example of how machine learning can be used to address part of that challenge.\n",
    "\n",
    "## About the prediction problem\n",
    "\n",
    "One critical property of a video is engagement: how interesting or \"engaging\" it is for viewers, so that they decide to keep watching. Engagement is critical for learning, whether the instruction is coming from a video or any other source. There are many ways to define engagement with video, but one common approach is to estimate it by measuring how much of the video a user watches. If the video is not interesting and does not engage a viewer, they will typically abandon it quickly, e.g. only watch 5 or 10% of the total. \n",
    "\n",
    "A first step towards providing the best-matching educational content is to understand which features of educational material make it engaging for learners in general. This is where predictive modeling can be applied, via supervised machine learning. For this assignment, your task is to predict how engaging an educational video is likely to be for viewers, based on a set of features extracted from the video's transcript, audio track, hosting site, and other sources.\n",
    "\n",
    "We chose this prediction problem for several reasons:\n",
    "\n",
    "* It combines a variety of features derived from a rich set of resources connected to the original data;\n",
    "* The manageable dataset size means the dataset and supervised models for it can be easily explored on a wide variety of computing platforms;\n",
    "* Predicting popularity or engagement for a media item, especially combined with understanding which features contribute to its success with viewers, is a fun problem but also a practical representative application of machine learning in a number of business and educational sectors.\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "\n",
    "We extracted training and test datasets of educational video features from the VLE Dataset put together by researcher Sahan Bulathwela at University College London. \n",
    "\n",
    "We provide you with two data files for use in training and validating your models: train.csv and test.csv. Each row in these two files corresponds to a single educational video, and includes information about diverse properties of the video content as described further below. The target variable is `engagement` which was defined as True if the median percentage of the video watched across all viewers was at least 30%, and False otherwise.\n",
    "\n",
    "Note: Any extra variables that may be included in the training set are simply for your interest if you want an additional source of data for visualization, or to enable unsupervised and semi-supervised approaches. However, they are not included in the test set and thus cannot be used for prediction. **Only the data already included in your Coursera directory can be used for training the model for this assignment.**\n",
    "\n",
    "For this final assignment, you will bring together what you've learned across all four weeks of this course, by exploring different prediction models for this new dataset. In addition, we encourage you to apply what you've learned about model selection to do hyperparameter tuning using training/validation splits of the training data, to optimize the model and further increase its performance. In addition to a basic evaluation of model accuracy, we've also provided a utility function to visualize which features are most and least contributing to the overall model performance.\n",
    "\n",
    "**File descriptions** \n",
    "    assets/train.csv - the training set (Use only this data for training your model!)\n",
    "    assets/test.csv - the test set\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv:\n",
    "\n",
    "    title_word_count - the number of words in the title of the video.\n",
    "    \n",
    "    document_entropy - a score indicating how varied the topics are covered in the video, based on the transcript. Videos with smaller entropy scores will tend to be more cohesive and more focused on a single topic.\n",
    "    \n",
    "    freshness - The number of days elapsed between 01/01/1970 and the lecture published date. Videos that are more recent will have higher freshness values.\n",
    "    \n",
    "    easiness - A text difficulty measure applied to the transcript. A lower score indicates more complex language used by the presenter.\n",
    "    \n",
    "    fraction_stopword_presence - A stopword is a very common word like 'the' or 'and'. This feature computes the fraction of all words that are stopwords in the video lecture transcript.\n",
    "    \n",
    "    speaker_speed - The average speaking rate in words per minute of the presenter in the video.\n",
    "    \n",
    "    silent_period_rate - The fraction of time in the lecture video that is silence (no speaking).\n",
    "    \n",
    "train.csv only:\n",
    "    \n",
    "    engagement - Target label for training. True if learners watched a substantial portion of the video (see description), or False otherwise.\n",
    "    \n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Your predictions will be given as the probability that the corresponding video will be engaging to learners.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC). \n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model with an AUC (area under ROC curve) of at least 0.8 passes this assignment, and over 0.85 will receive full points.\n",
    "___\n",
    "\n",
    "For this assignment, create a function that trains a model to predict significant learner engagement with a video using `asset/train.csv`. Using this model, return a Pandas Series object of length 2309 with the data being the probability that each corresponding video from `readonly/test.csv` will be engaging (according to a model learned from the 'engagement' label in the training set), and the video index being in the `id` field.\n",
    "\n",
    "Example:\n",
    "\n",
    "    id\n",
    "       9240    0.401958\n",
    "       9241    0.105928\n",
    "       9242    0.018572\n",
    "                 ...\n",
    "       9243    0.208567\n",
    "       9244    0.818759\n",
    "       9245    0.018528\n",
    "             ...\n",
    "       Name: engagement, dtype: float32\n",
    "       \n",
    "### Hints\n",
    "\n",
    "* Make sure your code is working before submitting it to the autograder.\n",
    "\n",
    "* Print out and check your result to see whether there is anything weird (e.g., all probabilities are the same).\n",
    "\n",
    "* Generally the total runtime should be less than 10 mins. \n",
    "\n",
    "* Try to avoid global variables. If you have other functions besides engagement_model, you should move those functions inside the scope of engagement_model.\n",
    "\n",
    "* Be sure to first check the pinned threads in Week 4's discussion forum if you run into a problem you can't figure out.\n",
    "\n",
    "### Extensions\n",
    "\n",
    "* If this prediction task motivates you to explore further, you can find more details here on the original VLE dataset and others related to video engagement: https://github.com/sahanbull/VLE-Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da02c5-f19b-45b2-8f1a-9d40f872add3",
   "metadata": {},
   "source": [
    "Steps for Solving the Assignment: (My plan)\n",
    "1) Data Preprocessing:\n",
    "Load the data: First, load the training and test datasets (train.csv and test.csv) using pandas.\n",
    "Handle missing values: Check for any missing values in the data and decide how to handle them (either by imputing, dropping, or filling them).\n",
    "Feature Scaling/Normalization: Normalize or scale continuous features to improve model performance (especially important for models like SVMs, logistic regression, etc.).\n",
    "Feature Encoding: If any features are categorical, we will need to encode them (though based on the description, it seems that all features are numeric).\n",
    "\n",
    "2) Model Training:\n",
    "Select models: Try multiple supervised machine learning models. Common choices for this kind of task include:\n",
    "Logistic Regression\n",
    "Random Forest Classifier\n",
    "Gradient Boosting (e.g., XGBoost, LightGBM)\n",
    "Support Vector Machine (SVM)\n",
    "Neural Networks (if feasible)\n",
    "Train a model: Train a classifier on the train.csv dataset using the features provided (excluding the target column engagement).\n",
    "\n",
    "3) Hyperparameter Tuning (optional):\n",
    "Hyperparameter tuning: Use techniques such as GridSearchCV or RandomizedSearchCV to tune hyperparameters of the model to improve its performance.\n",
    "Optimization: Fine-tune hyperparameters like the number of trees (for Random Forests or Gradient Boosting), learning rate, max depth, etc.\n",
    "\n",
    "4) Model Evaluation:\n",
    "AUC Metric: The evaluation metric for this assignment is the Area Under the ROC Curve (AUC). Ensure to evaluate the models based on this metric.\n",
    "Cross-validation: Use cross-validation on the training set to get a reliable estimate of model performance and avoid overfitting.\n",
    "\n",
    "5) Model Prediction on Test Data:\n",
    "Generate predictions: Once the best model is selected, use it to predict engagement probabilities for the videos in the test.csv dataset.\n",
    "Return results: Format the output as a Pandas Series with the id field and the predicted probabilities of engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1218318f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7dc38d94db79fb7160854a629c825a8",
     "grade": false,
     "grade_id": "cell-2c0cf4e0ffe5f447",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)   # Do not change this value: required to be compatible with solutions generated by the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd54a113-0d43-459f-b28d-5ebbeec23061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72035de3-021e-416f-8d48-d186823b9259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>document_entropy</th>\n",
       "      <th>freshness</th>\n",
       "      <th>easiness</th>\n",
       "      <th>fraction_stopword_presence</th>\n",
       "      <th>normalization_rate</th>\n",
       "      <th>speaker_speed</th>\n",
       "      <th>silent_period_rate</th>\n",
       "      <th>engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7.753995</td>\n",
       "      <td>16310</td>\n",
       "      <td>75.583936</td>\n",
       "      <td>0.553664</td>\n",
       "      <td>0.034049</td>\n",
       "      <td>2.997753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8.305269</td>\n",
       "      <td>15410</td>\n",
       "      <td>86.870523</td>\n",
       "      <td>0.584498</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>2.635789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.965583</td>\n",
       "      <td>15680</td>\n",
       "      <td>81.915968</td>\n",
       "      <td>0.605685</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>2.538095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8.142877</td>\n",
       "      <td>15610</td>\n",
       "      <td>80.148937</td>\n",
       "      <td>0.593664</td>\n",
       "      <td>0.016873</td>\n",
       "      <td>2.259055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.161250</td>\n",
       "      <td>14920</td>\n",
       "      <td>76.907549</td>\n",
       "      <td>0.581637</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8.182952</td>\n",
       "      <td>16180</td>\n",
       "      <td>76.684133</td>\n",
       "      <td>0.575290</td>\n",
       "      <td>0.023649</td>\n",
       "      <td>2.244809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8.101635</td>\n",
       "      <td>12760</td>\n",
       "      <td>85.303173</td>\n",
       "      <td>0.600232</td>\n",
       "      <td>0.018423</td>\n",
       "      <td>2.458497</td>\n",
       "      <td>0.196126</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7.733064</td>\n",
       "      <td>11460</td>\n",
       "      <td>97.572190</td>\n",
       "      <td>0.687275</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>1.992327</td>\n",
       "      <td>0.289208</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8.219794</td>\n",
       "      <td>15070</td>\n",
       "      <td>87.008975</td>\n",
       "      <td>0.600454</td>\n",
       "      <td>0.018557</td>\n",
       "      <td>1.715436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7.714182</td>\n",
       "      <td>14840</td>\n",
       "      <td>88.650478</td>\n",
       "      <td>0.617900</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>2.210577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  title_word_count  document_entropy  freshness   easiness  \\\n",
       "0   1                 9          7.753995      16310  75.583936   \n",
       "1   2                 6          8.305269      15410  86.870523   \n",
       "2   3                 3          7.965583      15680  81.915968   \n",
       "3   4                 9          8.142877      15610  80.148937   \n",
       "4   5                 9          8.161250      14920  76.907549   \n",
       "5   6                10          8.182952      16180  76.684133   \n",
       "6   7                10          8.101635      12760  85.303173   \n",
       "7   8                 9          7.733064      11460  97.572190   \n",
       "8   9                 7          8.219794      15070  87.008975   \n",
       "9  10                10          7.714182      14840  88.650478   \n",
       "\n",
       "   fraction_stopword_presence  normalization_rate  speaker_speed  \\\n",
       "0                    0.553664            0.034049       2.997753   \n",
       "1                    0.584498            0.018763       2.635789   \n",
       "2                    0.605685            0.030720       2.538095   \n",
       "3                    0.593664            0.016873       2.259055   \n",
       "4                    0.581637            0.023412       2.420000   \n",
       "5                    0.575290            0.023649       2.244809   \n",
       "6                    0.600232            0.018423       2.458497   \n",
       "7                    0.687275            0.008956       1.992327   \n",
       "8                    0.600454            0.018557       1.715436   \n",
       "9                    0.617900            0.018933       2.210577   \n",
       "\n",
       "   silent_period_rate  engagement  \n",
       "0            0.000000        True  \n",
       "1            0.000000       False  \n",
       "2            0.000000       False  \n",
       "3            0.000000       False  \n",
       "4            0.000000       False  \n",
       "5            0.000000       False  \n",
       "6            0.196126       False  \n",
       "7            0.289208       False  \n",
       "8            0.000000       False  \n",
       "9            0.000000       False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('assets/train.csv') # in training dataset have extra column \"engagement\" which is the target \n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d9e89c-f358-425a-b086-ce81f74cc027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>document_entropy</th>\n",
       "      <th>freshness</th>\n",
       "      <th>easiness</th>\n",
       "      <th>fraction_stopword_presence</th>\n",
       "      <th>normalization_rate</th>\n",
       "      <th>speaker_speed</th>\n",
       "      <th>silent_period_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9240</td>\n",
       "      <td>6</td>\n",
       "      <td>8.548351</td>\n",
       "      <td>14140</td>\n",
       "      <td>89.827395</td>\n",
       "      <td>0.640810</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>2.262723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9241</td>\n",
       "      <td>8</td>\n",
       "      <td>7.730110</td>\n",
       "      <td>14600</td>\n",
       "      <td>82.446667</td>\n",
       "      <td>0.606738</td>\n",
       "      <td>0.027708</td>\n",
       "      <td>2.690351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9242</td>\n",
       "      <td>3</td>\n",
       "      <td>8.200887</td>\n",
       "      <td>16980</td>\n",
       "      <td>88.821542</td>\n",
       "      <td>0.621089</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>3.116071</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9243</td>\n",
       "      <td>5</td>\n",
       "      <td>6.377299</td>\n",
       "      <td>16260</td>\n",
       "      <td>86.874660</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>2.837500</td>\n",
       "      <td>0.017994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9244</td>\n",
       "      <td>18</td>\n",
       "      <td>7.756530</td>\n",
       "      <td>14030</td>\n",
       "      <td>88.872277</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.033240</td>\n",
       "      <td>1.354839</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9245</td>\n",
       "      <td>13</td>\n",
       "      <td>7.941503</td>\n",
       "      <td>14750</td>\n",
       "      <td>83.918688</td>\n",
       "      <td>0.624874</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>2.381301</td>\n",
       "      <td>0.233458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9246</td>\n",
       "      <td>20</td>\n",
       "      <td>7.676826</td>\n",
       "      <td>14750</td>\n",
       "      <td>78.835570</td>\n",
       "      <td>0.603597</td>\n",
       "      <td>0.035575</td>\n",
       "      <td>1.731507</td>\n",
       "      <td>0.249336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9247</td>\n",
       "      <td>8</td>\n",
       "      <td>8.046349</td>\n",
       "      <td>14070</td>\n",
       "      <td>85.396646</td>\n",
       "      <td>0.635028</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>3.080714</td>\n",
       "      <td>0.168078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9248</td>\n",
       "      <td>13</td>\n",
       "      <td>6.398993</td>\n",
       "      <td>14850</td>\n",
       "      <td>97.891938</td>\n",
       "      <td>0.728659</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>1.106897</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9249</td>\n",
       "      <td>9</td>\n",
       "      <td>8.310242</td>\n",
       "      <td>14200</td>\n",
       "      <td>79.556191</td>\n",
       "      <td>0.590176</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>1.889474</td>\n",
       "      <td>0.292243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  title_word_count  document_entropy  freshness   easiness  \\\n",
       "0  9240                 6          8.548351      14140  89.827395   \n",
       "1  9241                 8          7.730110      14600  82.446667   \n",
       "2  9242                 3          8.200887      16980  88.821542   \n",
       "3  9243                 5          6.377299      16260  86.874660   \n",
       "4  9244                18          7.756530      14030  88.872277   \n",
       "5  9245                13          7.941503      14750  83.918688   \n",
       "6  9246                20          7.676826      14750  78.835570   \n",
       "7  9247                 8          8.046349      14070  85.396646   \n",
       "8  9248                13          6.398993      14850  97.891938   \n",
       "9  9249                 9          8.310242      14200  79.556191   \n",
       "\n",
       "   fraction_stopword_presence  normalization_rate  speaker_speed  \\\n",
       "0                    0.640810            0.017945       2.262723   \n",
       "1                    0.606738            0.027708       2.690351   \n",
       "2                    0.621089            0.009857       3.116071   \n",
       "3                    0.600000            0.004348       2.837500   \n",
       "4                    0.616105            0.033240       1.354839   \n",
       "5                    0.624874            0.013074       2.381301   \n",
       "6                    0.603597            0.035575       1.731507   \n",
       "7                    0.635028            0.021921       3.080714   \n",
       "8                    0.728659            0.024390       1.106897   \n",
       "9                    0.590176            0.025293       1.889474   \n",
       "\n",
       "   silent_period_rate  \n",
       "0            0.000000  \n",
       "1            0.000000  \n",
       "2            0.000000  \n",
       "3            0.017994  \n",
       "4            0.000000  \n",
       "5            0.233458  \n",
       "6            0.249336  \n",
       "7            0.168078  \n",
       "8            0.000000  \n",
       "9            0.292243  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('assets/test.csv')\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d179ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aef89dbca058b3768c5e369581c14bbb",
     "grade": false,
     "grade_id": "cell-f8da4477c345bf17",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. AUC):  {'max_depth': 10, 'n_estimators': 100}\n",
      "Grid best score (AUC):  0.8649993504665725\n",
      "Best Estimator (Model): RandomForestClassifier(max_depth=10, random_state=999)\n",
      "Training Accuracy of the Best Model: 0.9629830068189198\n",
      "Training Precision of the Best Model: 0.8707653701380176\n",
      "Training Recall of the Best Model: 0.7736900780379041\n",
      "Training F1 Score of the Best Model: 0.8193624557260921\n",
      "Cross-validation AUC scores: [0.89870104 0.87771783 0.88862297 0.89351667 0.76643825]\n",
      "Mean AUC score: 0.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "9240     0.042783\n",
       "9241     0.068065\n",
       "9242     0.270520\n",
       "9243     0.866969\n",
       "9244     0.131426\n",
       "           ...   \n",
       "11544    0.043442\n",
       "11545    0.008248\n",
       "11546    0.009410\n",
       "11547    0.837368\n",
       "11548    0.026534\n",
       "Name: engagement, Length: 2309, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def engagement_model():\n",
    "    # YOUR CODE HERE\n",
    " \n",
    "    # Step 1: Load the data\n",
    "    train_data = pd.read_csv('assets/train.csv')\n",
    "    test_data = pd.read_csv('assets/test.csv')\n",
    "\n",
    "    # Step 2: Preprocessing\n",
    "    X_train = train_data.drop(columns = ['engagement']) # In training dataset have extra column \"engagement\" which is the target \n",
    "    y_train = train_data['engagement'] #Target column\n",
    "    \n",
    "    X_test = test_data \n",
    "    # Since the test set doesn't contain the engagement column, you're right that we cannot compute the ROC curve directly with that data. \n",
    "    # The confusion arises from the fact that your task involves predicting engagement for the test data (i.e., predicting whether the video will be engaging or not). \n",
    "    # However, for the evaluation of your model, the ROC curve needs the true engagement labels (y_test), which are only available in the training data.\n",
    "\n",
    "    # Feature Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Step 3: Model Training (Using Random Forest Classifier as an example)\n",
    "    RF_clf = RandomForestClassifier(n_estimators=100, random_state=999)\n",
    "    RF_clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Step 4: Hyperparameter Tuning (Optional)\n",
    "    # Perform grid search or random search for hyperparameter tuning if needed.\n",
    "    grid_values = {'n_estimators': [100, 200], 'max_depth': [2, 5, 10]}\n",
    "    grid_search = GridSearchCV(estimator = RF_clf, param_grid = grid_values, cv = 5, scoring = 'roc_auc', n_jobs = -1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print('Grid best parameter (max. AUC): ', grid_search.best_params_)\n",
    "    print('Grid best score (AUC): ', grid_search.best_score_)\n",
    "\n",
    "    \n",
    "    # Step 6: Use the best estimator from GridSearchCV for predictions\n",
    "    best_model = grid_search.best_estimator_  # Use the model with best parameters from grid search\n",
    "    print(\"Best Estimator (Model): {}\".format(best_model))\n",
    "    \n",
    " \n",
    "    \n",
    "    # Evaluate on training data. Typically, when evaluating a machine learning model, metrics like accuracy, precision, recall, F1-score, etc., should be applied to the test data, not the training data.\n",
    "    # But in our this example, we do not have testing data i.e. y_test.\n",
    "    y_train_pred = best_model.predict_proba(X_train_scaled)[:, 1]\n",
    "    \n",
    "    # Evaluate on Training Data with Lowered decision threshold because initially the training recall results is too low at Recall: 63.8%. Implication: The remaining 36.2% of the true positive cases are being missed by the model — they are incorrectly predicted as negative (false negatives).\n",
    "    threshold = 0.3\n",
    "    y_train_pred_lower_threshold = (y_train_pred >= threshold).astype(int)  # Classify based on new threshold\n",
    "    \n",
    "    # The reason train_accuracy uses y_train is that we are evaluating the model's performance on the training data, where we already know the true labels.\n",
    "    # Training accuracy measures how well the model performs on the data it has seen during training. In this case, y_train represents the true labels (ground truth) for the training data, and y_train_pred represents the model's predictions on the same data.\n",
    "    train_accuracy = best_model.score(X_train_scaled, y_train) # Accuracy: proportion of correct predictions\n",
    "    # is the same as train_accuracy_function = accuracy_score(y_train, y_train_pred), just that using this method will require y_train and y_train_pred as input\n",
    "    \n",
    "    # Using y_train directly (but since we do not have y_test engagement - Target label) wouldn't make sense for metrics like precision, recall, and F1-score because these metrics are designed to evaluate how well the model’s predictions (i.e., y_train_pred) match the true labels (i.e., y_train). \n",
    "    # If you were to use y_train as both the predicted and true labels, it would trivially give you a perfect score for precision, recall, and F1 (since true labels and predictions would be identical).\n",
    "    precision = precision_score(y_train, y_train_pred_lower_threshold) # Precision: proportion of true positives among positive predictions\n",
    "    recall = recall_score(y_train, y_train_pred_lower_threshold)  # Recall: proportion of true positives among actual positives\n",
    "    f1 = f1_score(y_train, y_train_pred_lower_threshold) # F1-score: harmonic mean of precision and recall\n",
    "    # Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "    # Precision = TP / (TP + FP)\n",
    "    # Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "    # F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "    # Performance metric of the best model using training data. \n",
    "    print(\"Training Accuracy of the Best Model: {}\".format(train_accuracy))\n",
    "    print(\"Training Precision of the Best Model: {}\".format(precision))\n",
    "    print(\"Training Recall of the Best Model: {}\".format(recall))\n",
    "    print(\"Training F1 Score of the Best Model: {}\".format(f1))\n",
    "    \n",
    "    # Cross-validation AUC scores of best model using training data. Unlike the above performance metrics, cross_val_score is used on the training data to assess the model's performance during training and help with model selection.\n",
    "    cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv = 5, scoring = 'roc_auc', n_jobs = -1)\n",
    "    print(\"Cross-validation AUC scores: {}\".format(cv_scores))\n",
    "    print(\"Mean AUC score: {:.4f}\".format(cv_scores.mean()))\n",
    "    \n",
    "    # Step 7: Predictions on the test set\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    # Predict probabilities of engagement\n",
    "    predictions_proba = best_model.predict_proba(X_test_scaled)[:, 1]  # We want the probability for the positive class (engaged)\n",
    "     \n",
    "    # Step 8: Format the output\n",
    "    results = pd.Series(predictions_proba, index = test_data['id'], name = 'engagement')\n",
    "    \n",
    "    return results\n",
    "\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "engagement_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c78d565a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3b639d19639542702a374e84b2efb8e",
     "grade": false,
     "grade_id": "cell-ee9c764493852fe4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. AUC):  {'max_depth': 10, 'n_estimators': 100}\n",
      "Grid best score (AUC):  0.8649993504665725\n",
      "Best Estimator (Model): RandomForestClassifier(max_depth=10, random_state=999)\n",
      "Training Accuracy of the Best Model: 0.9629830068189198\n",
      "Training Precision of the Best Model: 0.8707653701380176\n",
      "Training Recall of the Best Model: 0.7736900780379041\n",
      "Training F1 Score of the Best Model: 0.8193624557260921\n",
      "Cross-validation AUC scores: [0.89870104 0.87771783 0.88862297 0.89351667 0.76643825]\n",
      "Mean AUC score: 0.8650\n"
     ]
    }
   ],
   "source": [
    "stu_ans = engagement_model()\n",
    "assert isinstance(stu_ans, pd.Series), \"Your function should return a pd.Series. \"\n",
    "assert len(stu_ans) == 2309, \"Your series is of incorrect length: expected 2309 \"\n",
    "assert np.issubdtype(stu_ans.index.dtype, np.integer), \"Your answer pd.Series should have an index of integer type representing video id.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6c9cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdbc39782ccccaa72a7a808b9025bba9",
     "grade": true,
     "grade_id": "cell-0372cfb70ab9b4de",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42118464",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26a7c364781ea24c8e46c623e73c1d4a",
     "grade": true,
     "grade_id": "cell-df6ac3eec5bb54f7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
